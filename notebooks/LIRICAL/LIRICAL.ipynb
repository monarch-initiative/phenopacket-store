{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f88f70c-970a-43d2-b03c-1b0676ad22bc",
   "metadata": {},
   "source": [
    "<h1>Convert LIRICAL's 384 Phenopackets to GA4GH Version 2 Format</h1>\n",
    "<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/32755546/\" target=\"__blank\">Robinson PN, et al. (2020) Interpretable Clinical Genomics with a Likelihood Ratio Paradigm. Am J Hum Genet. 2020 Sep 3;107(3):403-417</a> presented 384 phenopackets formated according to the GA4GH Phenopacket Schema version 1. This notebook converts those phenopackets to version 2 of the Phenopacket Schema.</p>\n",
    "<p>We use the Python json package to input the V1 phenopackets and apply a series of corrections to ensure the V2 phenopackets are correctly formated.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33a1010e-60e4-4a96-b153-7a8cc9d9a5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyphetools version 0.9.4\n"
     ]
    }
   ],
   "source": [
    "import phenopackets as PPKt\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from google import protobuf\n",
    "from google.protobuf.json_format import MessageToJson\n",
    "import time\n",
    "import hpotk\n",
    "from pyphetools.validation import *\n",
    "from pyphetools.visualization import *\n",
    "from pyphetools.creation import Individual\n",
    "import pyphetools\n",
    "print(f\"pyphetools version {pyphetools.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3ce5a5-0677-4c32-82cd-9df4b5312987",
   "metadata": {},
   "source": [
    "<h2>Import HPO object</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a154a8eb-6f41-44d6-9e37-060dfa464169",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo = hpotk.load_ontology('http://purl.obolibrary.org/obo/hp.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff6443-3ae0-4603-9f62-7f8c956a92b5",
   "metadata": {},
   "source": [
    "### Get all 384 json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa8afc86-540a-4a59-8328-6bcb4746336b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted total of 384 V1 Phenopacket V1 files\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "v1dir = \"v1ppkts\"\n",
    "jsonfiles = [f for f in listdir(v1dir) if isfile(join(v1dir, f)) and f.endswith(\"json\")]\n",
    "print(f\"Extracted total of {len(jsonfiles)} V1 Phenopacket V1 files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2659b-9ac5-4e5e-a683-3194bc56a82a",
   "metadata": {},
   "source": [
    "### Create JSON objects from JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d42f9eb-f80e-4c51-b6dc-dc22d07ad8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_object(fname, dirname):\n",
    "    fpath = join(dirname, fname)\n",
    "    if not isfile(fpath):\n",
    "        raise FileNotFoundError(f\"Could not find {fpath}\")\n",
    "    with open(fpath, \"r\") as f:\n",
    "        json_string = f.read()\n",
    "        json_dict = json.loads(json_string)\n",
    "        return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d1c6d3-cdf1-469a-a4d0-c5bf416b95f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(json_dict):\n",
    "    if 'id' not in json_dict:\n",
    "        raise ValueError(\"Could not extract id field\")\n",
    "    else:\n",
    "        return json_dict.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3417ffd0-1859-4a35-bd2f-99d2a6d24517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_age(ageString):\n",
    "    \"\"\"\n",
    "    return true if we can parse age as an ISO 8601 Period\n",
    "    \"\"\"\n",
    "    if ageString == \"N/A\":\n",
    "        return False\n",
    "    # first check if the string contains digits\n",
    "    _digits = re.compile('\\d')\n",
    "    if not bool(_digits.search(ageString)):\n",
    "        print(f\"invalid ageString {ageString}\")\n",
    "        return False\n",
    "    # now check that the string conforms to ISO 8601, e.g. P34Y2M\n",
    "    match = re.match(\n",
    "        r'P((?P<years>\\d+)Y)?((?P<months>\\d+)M)?((?P<weeks>\\d+)W)?((?P<days>\\d+)D)?(T((?P<hours>\\d+)H)?((?P<minutes>\\d+)M)?((?P<seconds>\\d+)S)?)?',\n",
    "        ageString\n",
    "    )\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a68ac7-335d-4154-a16e-5c5376e3f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject(json_dict):\n",
    "    if 'subject' not in json_dict:\n",
    "        raise ValueError(\"Could not extract id field\")\n",
    "    subject = json_dict.get('subject')\n",
    "    proband_id = subject.get('id', None)\n",
    "    ageAtCollection = subject.get('ageAtCollection', None)\n",
    "    invalid_age_strings = { \"N/A\", \"ADULT\", \"FETUS\" }\n",
    "    if ageAtCollection is not None:\n",
    "        iso_age = ageAtCollection.get('age', None)\n",
    "        iso_age = iso_age.upper()\n",
    "        if not iso_age in invalid_age_strings:\n",
    "            if not iso_age.startswith(\"P\"): \n",
    "                iso_age = \"P\" + iso_age\n",
    "            if not validate_age(iso_age):\n",
    "                print(f\"Could not validate age for {proband_id}: \\\"{iso_age}\\\", will omit\")\n",
    "                iso_age = None\n",
    "    else:\n",
    "        iso_age = None\n",
    "        \n",
    "    sex = subject.get('sex', 'UNKNOWN_SEX')\n",
    "    return proband_id, iso_age, sex\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83698bb-a15f-4a6c-81eb-cf10c93bde09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phenotypic_features_list(json_dict):\n",
    "    if 'phenotypicFeatures' not in json_dict:\n",
    "        raise ValueError(\"Could not extract phenotypicFeatures field\")\n",
    "    pfeature_list = []\n",
    "    for pfeat in json_dict.get('phenotypicFeatures'):\n",
    "        pfeature = PPKt.PhenotypicFeature()\n",
    "        ontology_term = pfeat.get('type')\n",
    "        ontology_id = ontology_term.get('id')\n",
    "        ontology_label = ontology_term.get('label')\n",
    "        # The following code uses the HPO to update outdated term IDs and labels\n",
    "        if ontology_id in hpo:\n",
    "            hpo_term = hpo.get_term(ontology_id)\n",
    "            ontology_id = hpo_term.identifier\n",
    "            ontology_label = hpo_term.name\n",
    "        hpo_term = PPKt.OntologyClass()\n",
    "        hpo_term.id = ontology_id.value\n",
    "        hpo_term.label = ontology_label\n",
    "        pfeature.type.CopyFrom(hpo_term)\n",
    "        if 'excluded' in pfeat:\n",
    "            pfeature.excluded = pfeat.excluded\n",
    "        evidence_list = pfeat.get('evidence')\n",
    "        # The 384 v1 phenopackets always have exactly one evidence element\n",
    "        # do not check here, things will crash if we were wrong\n",
    "        evidence = evidence_list[0]\n",
    "        evidence_code = evidence.get('evidenceCode')\n",
    "        evidence_term = PPKt.OntologyClass()\n",
    "        evidence_term.id = evidence_code.get('id')\n",
    "        evidence_term.label = evidence_code.get('label')\n",
    "        evi = PPKt.Evidence()\n",
    "        evi.evidence_code.CopyFrom(evidence_term)\n",
    "        reference_json = evidence.get('reference')\n",
    "        if reference_json is not None:\n",
    "            ref = PPKt.ExternalReference()\n",
    "            ref.id = reference_json.get('id')\n",
    "            ref.description = reference_json.get('description')\n",
    "            evi.reference.CopyFrom(ref)\n",
    "        pfeature.evidence.append(evi)\n",
    "        pfeature_list.append(pfeature)\n",
    "    return pfeature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ecee5-e97a-4e6a-ae0e-7a360b6b36ae",
   "metadata": {},
   "source": [
    "<h2>Disease</h2>\n",
    "<p>This is the format of the disease entries in the V1 schema.</p>\n",
    "<pre>'diseases': [{'term': {'id': 'OMIM:191900', 'label': 'MUCKLE-WELLS SYNDROME; MWS'}}]</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717b8899-3fa3-4712-b8ae-cbedbc6f183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disease(json_dict):\n",
    "    if not 'diseases' in json_dict:\n",
    "        raise ValueError(\"Could not extract disease field\")\n",
    "    disease_list = json_dict.get('diseases')\n",
    "    if len(disease_list) != 1:\n",
    "        raise ValueError(f\"Got bad number of diseases, {len(disease_list)}\")\n",
    "    disease_object = disease_list[0]\n",
    "    return disease_object.get('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ab9fdb-2ee1-4d68-87e8-d78a09295f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene(json_dict):\n",
    "    \"\"\"\n",
    "    We expect one and only one gene here\n",
    "    \"\"\"\n",
    "    if not 'genes' in json_dict:\n",
    "        raise ValueError(\"Could not extract genes field\")\n",
    "    gene_list = json_dict.get('genes')\n",
    "    if len(gene_list) != 1:\n",
    "        raise ValueError(f\"Got bad number of genes, {len(gene_list)}\")\n",
    "    return gene_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f2a698-1931-414d-abcd-c0d5ec64b2a8",
   "metadata": {},
   "source": [
    "<h2>Variants in v1 phenopacket</h2>\n",
    "<p>This is the format of the variants entries in the V1 schema.</p>\n",
    "\n",
    "<pre>\n",
    " 'variants': [{'vcfAllele': {'genomeAssembly': 'GRCh37', 'chr': '1', 'pos': 247587794, 'ref': 'C', 'alt': 'T'}, \n",
    "    'zygosity': {'id': 'GENO:0000135', 'label': 'heterozygous'}}]\n",
    " </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c488dc42-0868-49e0-8f4d-286c1c8dead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_ga4gh_interpretation(vcf_allele, zygosity, gene, disease, var_id):\n",
    "    vdescriptor = PPKt.VariationDescriptor()\n",
    "    vdescriptor.id = var_id\n",
    "    vdescriptor.gene_context.value_id = gene.get('id')\n",
    "    vdescriptor.gene_context.symbol = gene.get('symbol')\n",
    "    vdescriptor.molecule_context =  PPKt.MoleculeContext.genomic\n",
    "    vdescriptor.allelic_state.id = zygosity.get('id')\n",
    "    vdescriptor.allelic_state.label = zygosity.get('label')\n",
    "    vinterpretation = PPKt.VariantInterpretation() \n",
    "    vcf_record = PPKt.VcfRecord()\n",
    "    vcf_record.genome_assembly =  vcf_allele.get('genomeAssembly')\n",
    "    vcf_record.chrom = vcf_allele.get('chr')\n",
    "    vcf_record.pos = vcf_allele.get('pos')\n",
    "    vcf_record.ref = vcf_allele.get('ref')\n",
    "    vcf_record.alt = vcf_allele.get('alt')\n",
    "    vdescriptor.vcf_record.CopyFrom(vcf_record)\n",
    "    vinterpretation.variation_descriptor.CopyFrom(vdescriptor)\n",
    "    return vinterpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f89c45dc-5e3d-421e-9633-3963754b21df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interpretation(json_dict, gene, disease, individual_id):\n",
    "    if not 'variants' in json_dict:\n",
    "        raise ValueError(\"Could not find variants\")\n",
    "    ga4gh_var_list = []\n",
    "    i = 0\n",
    "    for v in json_dict.get('variants'):\n",
    "        if 'vcfAllele' not in v:\n",
    "            raise ValueError(\"Malformed variant\")\n",
    "        if 'zygosity' not in v:\n",
    "            raise ValueError(\"Malformed variant - no zygosity\")\n",
    "        vcf_allele = v.get('vcfAllele')\n",
    "        zygosity = v.get('zygosity')\n",
    "        i += 1\n",
    "        var_id = f\"variant-{i}\"\n",
    "        ga4gh_int = get_one_ga4gh_interpretation(vcf_allele, zygosity, gene, disease, var_id)\n",
    "        ga4gh_var_list.append(ga4gh_int)\n",
    "    interpretation = PPKt.Interpretation()\n",
    "    interpretation.id = \"interpretation-id\"\n",
    "    interpretation.progress_status = PPKt.Interpretation.ProgressStatus.SOLVED\n",
    "    interpretation.diagnosis.disease.id = disease.get('id')\n",
    "    interpretation.diagnosis.disease.label = disease.get('label')\n",
    "    for var in ga4gh_var_list:\n",
    "        genomic_interpretation = PPKt.GenomicInterpretation()\n",
    "        genomic_interpretation.subject_or_biosample_id = individual_id\n",
    "        # by assumption, variants passed to this package are all causative\n",
    "        genomic_interpretation.interpretation_status = PPKt.GenomicInterpretation.InterpretationStatus.CAUSATIVE\n",
    "        genomic_interpretation.variant_interpretation.CopyFrom(var)\n",
    "        interpretation.diagnosis.genomic_interpretations.append(genomic_interpretation)\n",
    "    return interpretation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3146193-6f7a-490a-896d-be6ac5a37aaa",
   "metadata": {},
   "source": [
    "<h2>Metadata (V1)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abd90fb5-ca2e-439c-a338-a4bb25b1dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(json_dict):\n",
    "    if not 'metaData' in json_dict:\n",
    "        raise ValueError(\"Could not find metaData\")\n",
    "    metadata = json_dict.get('metaData')\n",
    "    createdBy = metadata.get('createdBy', 'n/a')\n",
    "    submittedBy = metadata.get('submittedBy')\n",
    "    ga4gh_metadata = PPKt.MetaData()\n",
    "    resources = []\n",
    "    for res in metadata.get('resources'):\n",
    "        if res.get('id') == 'ncbitaxon':\n",
    "            continue # superfluous to add taxon H. sapiens in thius context and we do not have iriPREFIX for this resource\n",
    "        ga4gh_resource = PPKt.Resource()\n",
    "        ga4gh_resource.id = res.get('id')\n",
    "        ga4gh_resource.name = res.get('name')\n",
    "        ga4gh_resource.url = res.get('url')\n",
    "        ga4gh_resource.version = res.get('version', 'n/a')\n",
    "        ga4gh_resource.namespace_prefix = res.get('namespacePrefix')\n",
    "        ga4gh_resource.iri_prefix = res.get('iriPrefix', 'n/a')\n",
    "        ga4gh_metadata.resources.append(ga4gh_resource)\n",
    "    ga4gh_metadata.created_by = createdBy\n",
    "    if submittedBy is not None:\n",
    "        ga4gh_metadata.submitted_by = submittedBy\n",
    "    now = time.time()\n",
    "    seconds = int(now)\n",
    "    nanos = int((now - seconds) * 10 ** 9)\n",
    "    timestamp = protobuf.timestamp_pb2.Timestamp(seconds=seconds, nanos=nanos)\n",
    "    ga4gh_metadata.created.CopyFrom(timestamp)\n",
    "    ga4gh_metadata.phenopacket_schema_version = \"2.0\"\n",
    "    for res in resources:\n",
    "        metadata.resources.append(res)\n",
    "    return ga4gh_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f948138e-c141-4ea5-b8b7-fded3a872389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_redundancies(hpo_term_ids):\n",
    "    \"\"\"\n",
    "    removes general ancestors if the theyhave a specific descendent germ in the same phenopacket.\n",
    "    \"\"\"\n",
    "    redundant_term_d = {}\n",
    "    hpo_term_id_set = set(hpo_term_ids)\n",
    "    if len(hpo_term_id_set) != len(hpo_term_ids):\n",
    "        print(\"found duplicates\")\n",
    "    for term_id1 in hpo_term_id_set:\n",
    "        for term_id2 in hpo_term_id_set:\n",
    "            # The ancestor, e.g. Seizure comes first, the other term, e.g. Clonic seizure, second\n",
    "            # in the following function call\n",
    "            if hpo.graph.is_ancestor_of(term_id2, term_id1):\n",
    "                redundant_term_d[term_id2] = term_id1\n",
    "    # When we get here, we have scanned all terms for redundant ancestors\n",
    "    non_redundant_terms = set([ tid for tid in hpo_term_ids if tid not in redundant_term_d])\n",
    "    #if len(redundant_term_d) > 0:\n",
    "    #    for term, descendant in redundant_term_d.items():\n",
    "    #        print(f\"Removing redundant_term {term} because of descendent {descendant}\")\n",
    "    return non_redundant_terms\n",
    "\n",
    "\n",
    "def get_clean_terms(pfeatures_list):\n",
    "    \"\"\"\n",
    "    remove terms that are redundant because there is a more specific descendent term\n",
    "    \"\"\"\n",
    "    observed_terms = [t for t in pfeatures_list if not t.excluded]\n",
    "    excluded_terms = [t for t in pfeatures_list if not t.excluded]\n",
    "    observed_d = {t.type.id:t for t in observed_terms}\n",
    "    excluded_d = {t.type.id:t for t in excluded_terms}\n",
    "    \n",
    "    observed_ids = fix_redundancies(observed_d.keys())\n",
    "    excluded_ids = fix_redundancies(excluded_d.keys())\n",
    "    clean_terms = []\n",
    "    # this will remove duplicates\n",
    "    seen_tids = set()\n",
    "    for tid in observed_ids:\n",
    "        if tid in seen_tids:\n",
    "            continue\n",
    "        else:\n",
    "            seen_tids.add(tid)\n",
    "        clean_terms.append(observed_d.get(tid))\n",
    "    for tid in excluded_ids:\n",
    "        if tid in seen_tids:\n",
    "            continue\n",
    "        else:\n",
    "            seen_tids.add(tid)\n",
    "        clean_terms.append(excluded_d.get(tid))    \n",
    "    return clean_terms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62022748-1fc4-47b2-b298-9d4443943510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_v2_phenopacket(json_dict):\n",
    "    id = get_id(json_dict)\n",
    "    proband_id, iso_age, sex= get_subject(json_dict)\n",
    "    pfeatures_list = get_phenotypic_features_list(json_dict)\n",
    "    pfeatures_list = get_clean_terms(pfeatures_list)\n",
    "    gene = get_gene(json_dict)\n",
    "    disease = get_disease(json_dict)\n",
    "    interpretation = get_interpretation(json_dict, gene, disease, proband_id)\n",
    "    # Create phenopacket\n",
    "    phenopacket = PPKt.Phenopacket()\n",
    "    phenopacket.id = id\n",
    "    proband = PPKt.Individual()\n",
    "    proband.id = proband_id\n",
    "    if sex == \"MALE\":\n",
    "        proband.sex  = PPKt.Sex.MALE\n",
    "    elif sex == \"FEMALE\":\n",
    "        proband.sex = PPKt.Sex.FEMALE\n",
    "    else:\n",
    "        proband.sex  = PPKt.Sex.UNKNOWN_SEX\n",
    "    if iso_age is not None:\n",
    "        proband.time_at_last_encounter.age.iso8601duration = iso_age\n",
    "    phenopacket.subject.CopyFrom(proband)\n",
    "    for pf in pfeatures_list:\n",
    "        phenopacket.phenotypic_features.append(pf)\n",
    "    phenopacket.interpretations.append(interpretation)\n",
    "    metadata = get_metadata(json_dict)\n",
    "    phenopacket.meta_data.CopyFrom(metadata)\n",
    "    return phenopacket\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be420e84-8e20-4ebf-b703-ab4b257e6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_phenopacket(json_dict, output_dir):\n",
    "    ppack = construct_v2_phenopacket(json_dict)\n",
    "    json_string = MessageToJson(ppack)\n",
    "    pp_id = ppack.id\n",
    "    fname = pp_id.replace(\" \", \"\").replace(\":\", \"_\")\n",
    "    fname = re.sub('[^A-Za-z0-9_-]', '', fname)  # remove any illegal characters from filename\n",
    "    fname = fname.replace(\" \", \"_\") + \".json\"\n",
    "    outpth = os.path.join(output_dir, fname)\n",
    "    with open(outpth, \"wt\") as fh:\n",
    "        fh.write(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1124962-d861-43be-be8a-8521fa2b3868",
   "metadata": {},
   "source": [
    "<h2>Output</h2>\n",
    "<p>Here we output the 384 phenopackets in version 2 format. Some of the original files do not have a valid age string, and so they produce a warning during the output. This can be ignored, the corresponding cases our output without an age (which is not required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdf192e7-66fe-4f70-bfdd-82688994bd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Output 384 phenopackets\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"v2phenopackets\"\n",
    "v1dir = \"v1ppkts\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "n = 0\n",
    "for json_file in jsonfiles:\n",
    "    json_dict = get_json_object(json_file, v1dir)\n",
    "    output_phenopacket(json_dict, out_dir)\n",
    "    print(\".\", end=\"\")\n",
    "    n += 1\n",
    "print(f\"\\nOutput {n} phenopackets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c535af8-e15e-4f84-890f-79df3df0cead",
   "metadata": {},
   "source": [
    "<h2>Additional validation</h2>\n",
    "<p>In the original phenopackets used for the LIRICAL publication, the original cases reports conmtained some redundant HPO terms.\n",
    "<p>This can be detected using <a href=\"http://phenopackets.org/phenopacket-tools/stable/cli.html\">phenopacket tools</a>.\n",
    "<p>We have removed duplicated and redundant terms using the above functions and the following call showed no errors</p>\n",
    "<pre>pxf validate --hpo hp.json *.json</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3af17457-c57e-4af2-a819-3a9b06043a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pyphetools] Ingested 384 GA4GH phenopackets.\n"
     ]
    }
   ],
   "source": [
    "ingestor = PhenopacketIngestor(indir=\"v2phenopackets\")\n",
    "ppkt_d = ingestor.get_phenopacket_dictionary()\n",
    "individuals = [Individual.from_ga4gh_phenopacket(ppkt) for ppkt in ppkt_d.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac8829cd-acda-48a7-a094-124985c4e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvalidator = CohortValidator(cohort=individuals, ontology=hpo, min_hpo=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed9bfe03-317c-428d-94cf-8e5c69c9cb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Cohort validation</h2>\n",
       "<p>No errors found for the cohort with 384 individuals</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "qc = QcVisualizer(cvalidator)\n",
    "display(HTML(qc.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a8e7a-09b8-4a70-8c31-8be303cf74eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
