{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f88f70c-970a-43d2-b03c-1b0676ad22bc",
   "metadata": {},
   "source": [
    "<h1>Convert LIRICAL's 384 Phenopackets to GA4GH Version 2 Format</h1>\n",
    "<p><a href=\"https://pubmed.ncbi.nlm.nih.gov/32755546/\" target=\"__blank\">Robinson PN, et al. (2020) Interpretable Clinical Genomics with a Likelihood Ratio Paradigm. Am J Hum Genet. 2020 Sep 3;107(3):403-417</a> presented 384 phenopackets formated according to the GA4GH Phenopacket Schema version 1. This notebook converts those phenopackets to version 2 of the Phenopacket Schema.</p>\n",
    "<p>We use the Python json package to input the V1 phenopackets and apply a series of corrections to ensure the V2 phenopackets are correctly formated.</p>\n",
    "<p>Note that we plan to revise all of these phenopackets and the version available in this notebook does not correspond to the original files. With time, all diseases will be treated separately and curations will be moved out of this folder to gene-specific folders.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a1010e-60e4-4a96-b153-7a8cc9d9a5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyphetools version 0.9.74\n"
     ]
    }
   ],
   "source": [
    "import phenopackets as PPKt\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from google import protobuf\n",
    "from google.protobuf.json_format import MessageToJson\n",
    "import time\n",
    "import hpotk\n",
    "from pyphetools.validation import *\n",
    "from pyphetools.visualization import *\n",
    "from pyphetools.creation import *\n",
    "import pyphetools\n",
    "print(f\"pyphetools version {pyphetools.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3ce5a5-0677-4c32-82cd-9df4b5312987",
   "metadata": {},
   "source": [
    "<h2>Import HPO object</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a154a8eb-6f41-44d6-9e37-060dfa464169",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo = hpotk.load_ontology('../hp.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff6443-3ae0-4603-9f62-7f8c956a92b5",
   "metadata": {},
   "source": [
    "### Get all 384 json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa8afc86-540a-4a59-8328-6bcb4746336b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted total of 384 V1 Phenopacket V1 files\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "v1dir = \"v1ppkts\"\n",
    "jsonfiles = [f for f in listdir(v1dir) if isfile(join(v1dir, f)) and f.endswith(\"json\")]\n",
    "print(f\"Extracted total of {len(jsonfiles)} V1 Phenopacket V1 files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2659b-9ac5-4e5e-a683-3194bc56a82a",
   "metadata": {},
   "source": [
    "### Create JSON objects from JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d42f9eb-f80e-4c51-b6dc-dc22d07ad8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_object(fname, dirname):\n",
    "    fpath = join(dirname, fname)\n",
    "    if not isfile(fpath):\n",
    "        raise FileNotFoundError(f\"Could not find {fpath}\")\n",
    "    with open(fpath, \"r\") as f:\n",
    "        json_string = f.read()\n",
    "        json_dict = json.loads(json_string)\n",
    "        return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d1c6d3-cdf1-469a-a4d0-c5bf416b95f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(json_dict):\n",
    "    if 'id' not in json_dict:\n",
    "        raise ValueError(\"Could not extract id field\")\n",
    "    else:\n",
    "        return json_dict.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3417ffd0-1859-4a35-bd2f-99d2a6d24517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_age(ageString):\n",
    "    \"\"\"\n",
    "    return true if we can parse age as an ISO 8601 Period\n",
    "    \"\"\"\n",
    "    if ageString == \"N/A\":\n",
    "        return False\n",
    "    # first check if the string contains digits\n",
    "    _digits = re.compile('\\d')\n",
    "    if not bool(_digits.search(ageString)):\n",
    "        print(f\"invalid ageString {ageString}\")\n",
    "        return False\n",
    "    # now check that the string conforms to ISO 8601, e.g. P34Y2M\n",
    "    match = re.match(\n",
    "        r'P((?P<years>\\d+)Y)?((?P<months>\\d+)M)?((?P<weeks>\\d+)W)?((?P<days>\\d+)D)?(T((?P<hours>\\d+)H)?((?P<minutes>\\d+)M)?((?P<seconds>\\d+)S)?)?',\n",
    "        ageString\n",
    "    )\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a68ac7-335d-4154-a16e-5c5376e3f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject(json_dict):\n",
    "    if 'subject' not in json_dict:\n",
    "        raise ValueError(\"Could not extract id field\")\n",
    "    subject = json_dict.get('subject')\n",
    "    proband_id = subject.get('id', None)\n",
    "    ageAtCollection = subject.get('ageAtCollection', None)\n",
    "    invalid_age_strings = { \"N/A\", \"ADULT\", \"FETUS\" }\n",
    "    if ageAtCollection is not None:\n",
    "        iso_age = ageAtCollection.get('age', None)\n",
    "        iso_age = iso_age.upper()\n",
    "        if not iso_age in invalid_age_strings:\n",
    "            if not iso_age.startswith(\"P\"):\n",
    "                iso_age = \"P\" + iso_age\n",
    "            if not validate_age(iso_age):\n",
    "                print(f\"Could not validate age for {proband_id}: \\\"{iso_age}\\\", will omit\")\n",
    "                iso_age = None\n",
    "    else:\n",
    "        iso_age = None\n",
    "\n",
    "    sex = subject.get('sex', 'UNKNOWN_SEX')\n",
    "    return proband_id, iso_age, sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83698bb-a15f-4a6c-81eb-cf10c93bde09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phenotypic_features_list(json_dict):\n",
    "    if 'phenotypicFeatures' not in json_dict:\n",
    "        raise ValueError(\"Could not extract phenotypicFeatures field\")\n",
    "    pfeature_list = []\n",
    "    for pfeat in json_dict.get('phenotypicFeatures'):\n",
    "        pfeature = PPKt.PhenotypicFeature()\n",
    "        ontology_term = pfeat.get('type')\n",
    "        ontology_id = ontology_term.get('id')\n",
    "        ontology_label = ontology_term.get('label')\n",
    "        # The following code uses the HPO to update outdated term IDs and labels\n",
    "        if ontology_id in hpo:\n",
    "            hpo_term = hpo.get_term(ontology_id)\n",
    "            ontology_id = hpo_term.identifier\n",
    "            ontology_label = hpo_term.name\n",
    "        hpo_term = PPKt.OntologyClass()\n",
    "        hpo_term.id = ontology_id.value\n",
    "        hpo_term.label = ontology_label\n",
    "        pfeature.type.CopyFrom(hpo_term)\n",
    "        if 'excluded' in pfeat:\n",
    "            pfeature.excluded = pfeat.excluded\n",
    "        evidence_list = pfeat.get('evidence')\n",
    "        # The 384 v1 phenopackets always have exactly one evidence element\n",
    "        # do not check here, things will crash if we were wrong\n",
    "        evidence = evidence_list[0]\n",
    "        evidence_code = evidence.get('evidenceCode')\n",
    "        evidence_term = PPKt.OntologyClass()\n",
    "        evidence_term.id = evidence_code.get('id')\n",
    "        evidence_term.label = evidence_code.get('label')\n",
    "        evi = PPKt.Evidence()\n",
    "        evi.evidence_code.CopyFrom(evidence_term)\n",
    "        reference_json = evidence.get('reference')\n",
    "        if reference_json is not None:\n",
    "            ref = PPKt.ExternalReference()\n",
    "            ref.id = reference_json.get('id')\n",
    "            ref.description = reference_json.get('description')\n",
    "            evi.reference.CopyFrom(ref)\n",
    "        pfeature.evidence.append(evi)\n",
    "        pfeature_list.append(pfeature)\n",
    "    return pfeature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ecee5-e97a-4e6a-ae0e-7a360b6b36ae",
   "metadata": {},
   "source": [
    "<h2>Disease</h2>\n",
    "<p>This is the format of the disease entries in the V1 schema.</p>\n",
    "<pre>'diseases': [{'term': {'id': 'OMIM:191900', 'label': 'MUCKLE-WELLS SYNDROME; MWS'}}]</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717b8899-3fa3-4712-b8ae-cbedbc6f183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disease(json_dict):\n",
    "    if not 'diseases' in json_dict:\n",
    "        raise ValueError(\"Could not extract disease field\")\n",
    "    disease_list = json_dict.get('diseases')\n",
    "    if len(disease_list) != 1:\n",
    "        raise ValueError(f\"Got bad number of diseases, {len(disease_list)}\")\n",
    "    disease_object = disease_list[0]\n",
    "    return disease_object.get('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ab9fdb-2ee1-4d68-87e8-d78a09295f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene(json_dict):\n",
    "    \"\"\"\n",
    "    We expect one and only one gene here\n",
    "    \"\"\"\n",
    "    if not 'genes' in json_dict:\n",
    "        raise ValueError(\"Could not extract genes field\")\n",
    "    gene_list = json_dict.get('genes')\n",
    "    if len(gene_list) != 1:\n",
    "        raise ValueError(f\"Got bad number of genes, {len(gene_list)}\")\n",
    "    return gene_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f2a698-1931-414d-abcd-c0d5ec64b2a8",
   "metadata": {},
   "source": [
    "<h2>Variants in v1 phenopacket</h2>\n",
    "<p>This is the format of the variants entries in the V1 schema.</p>\n",
    "\n",
    "<pre>\n",
    " 'variants': [{'vcfAllele': {'genomeAssembly': 'GRCh37', 'chr': '1', 'pos': 247587794, 'ref': 'C', 'alt': 'T'}, \n",
    "    'zygosity': {'id': 'GENO:0000135', 'label': 'heterozygous'}}]\n",
    " </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c488dc42-0868-49e0-8f4d-286c1c8dead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_ga4gh_interpretation(vcf_allele, zygosity, gene, disease, var_id):\n",
    "    vdescriptor = PPKt.VariationDescriptor()\n",
    "    vdescriptor.id = var_id\n",
    "    vdescriptor.gene_context.value_id = gene.get('id')\n",
    "    vdescriptor.gene_context.symbol = gene.get('symbol')\n",
    "    vdescriptor.molecule_context =  PPKt.MoleculeContext.genomic\n",
    "    vdescriptor.allelic_state.id = zygosity.get('id')\n",
    "    vdescriptor.allelic_state.label = zygosity.get('label')\n",
    "    vinterpretation = PPKt.VariantInterpretation()\n",
    "    vcf_record = PPKt.VcfRecord()\n",
    "    vcf_record.genome_assembly =  vcf_allele.get('genomeAssembly')\n",
    "    vcf_record.chrom = vcf_allele.get('chr')\n",
    "    vcf_record.pos = vcf_allele.get('pos')\n",
    "    vcf_record.ref = vcf_allele.get('ref')\n",
    "    vcf_record.alt = vcf_allele.get('alt')\n",
    "    vdescriptor.vcf_record.CopyFrom(vcf_record)\n",
    "    vinterpretation.variation_descriptor.CopyFrom(vdescriptor)\n",
    "    return vinterpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f89c45dc-5e3d-421e-9633-3963754b21df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interpretation(json_dict, gene, disease, individual_id):\n",
    "    if not 'variants' in json_dict:\n",
    "        raise ValueError(\"Could not find variants\")\n",
    "    ga4gh_var_list = []\n",
    "    i = 0\n",
    "    for v in json_dict.get('variants'):\n",
    "        if 'vcfAllele' not in v:\n",
    "            raise ValueError(\"Malformed variant\")\n",
    "        if 'zygosity' not in v:\n",
    "            raise ValueError(\"Malformed variant - no zygosity\")\n",
    "        vcf_allele = v.get('vcfAllele')\n",
    "        zygosity = v.get('zygosity')\n",
    "        i += 1\n",
    "        var_id = f\"variant-{i}\"\n",
    "        ga4gh_int = get_one_ga4gh_interpretation(vcf_allele, zygosity, gene, disease, var_id)\n",
    "        ga4gh_var_list.append(ga4gh_int)\n",
    "    interpretation = PPKt.Interpretation()\n",
    "    interpretation.id = \"interpretation-id\"\n",
    "    interpretation.progress_status = PPKt.Interpretation.ProgressStatus.SOLVED\n",
    "    interpretation.diagnosis.disease.id = disease.get('id')\n",
    "    interpretation.diagnosis.disease.label = disease.get('label')\n",
    "    for var in ga4gh_var_list:\n",
    "        genomic_interpretation = PPKt.GenomicInterpretation()\n",
    "        genomic_interpretation.subject_or_biosample_id = individual_id\n",
    "        # by assumption, variants passed to this package are all causative\n",
    "        genomic_interpretation.interpretation_status = PPKt.GenomicInterpretation.InterpretationStatus.CAUSATIVE\n",
    "        genomic_interpretation.variant_interpretation.CopyFrom(var)\n",
    "        interpretation.diagnosis.genomic_interpretations.append(genomic_interpretation)\n",
    "    return interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3146193-6f7a-490a-896d-be6ac5a37aaa",
   "metadata": {},
   "source": [
    "<h2>Metadata (V1)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abd90fb5-ca2e-439c-a338-a4bb25b1dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(json_dict):\n",
    "    if not 'metaData' in json_dict:\n",
    "        raise ValueError(\"Could not find metaData\")\n",
    "    metadata = json_dict.get('metaData')\n",
    "    createdBy = metadata.get('createdBy', 'n/a')\n",
    "    submittedBy = metadata.get('submittedBy')\n",
    "    ga4gh_metadata = PPKt.MetaData()\n",
    "    resources = []\n",
    "    for res in metadata.get('resources'):\n",
    "        if res.get('id') == 'ncbitaxon':\n",
    "            continue # superfluous to add taxon H. sapiens in thius context and we do not have iriPREFIX for this resource\n",
    "        ga4gh_resource = PPKt.Resource()\n",
    "        ga4gh_resource.id = res.get('id')\n",
    "        ga4gh_resource.name = res.get('name')\n",
    "        ga4gh_resource.url = res.get('url')\n",
    "        ga4gh_resource.version = res.get('version', 'n/a')\n",
    "        ga4gh_resource.namespace_prefix = res.get('namespacePrefix')\n",
    "        ga4gh_resource.iri_prefix = res.get('iriPrefix', 'n/a')\n",
    "        ga4gh_metadata.resources.append(ga4gh_resource)\n",
    "    ga4gh_metadata.created_by = createdBy\n",
    "    if submittedBy is not None:\n",
    "        ga4gh_metadata.submitted_by = submittedBy\n",
    "    now = time.time()\n",
    "    seconds = int(now)\n",
    "    nanos = int((now - seconds) * 10 ** 9)\n",
    "    timestamp = protobuf.timestamp_pb2.Timestamp(seconds=seconds, nanos=nanos)\n",
    "    ga4gh_metadata.created.CopyFrom(timestamp)\n",
    "    ga4gh_metadata.phenopacket_schema_version = \"2.0\"\n",
    "    for res in resources:\n",
    "        metadata.resources.append(res)\n",
    "    if \"externalReferences\" in metadata:\n",
    "        eref_list = metadata.get(\"externalReferences\")\n",
    "        if len(eref_list) == 1:\n",
    "            eref_1 = eref_list[0]\n",
    "            ga4gh_eref = PPKt.ExternalReference()\n",
    "            ga4gh_eref.id = eref_1.get(\"id\")\n",
    "            ga4gh_eref.description = eref_1.get(\"description\")\n",
    "            ga4gh_metadata.external_references.append(ga4gh_eref)\n",
    "        else:\n",
    "            print(f\"[ERROR] Malformed external references list with {len(eref_list)} entries\")\n",
    "    else:\n",
    "        print(f\"[ERROR] no external reference found for {metadata}\")\n",
    "    return ga4gh_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f948138e-c141-4ea5-b8b7-fded3a872389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_redundancies(hpo_term_ids):\n",
    "    \"\"\"\n",
    "    removes general ancestors if the theyhave a specific descendent germ in the same phenopacket.\n",
    "    \"\"\"\n",
    "    redundant_term_d = {}\n",
    "    hpo_term_id_set = set(hpo_term_ids)\n",
    "    if len(hpo_term_id_set) != len(hpo_term_ids):\n",
    "        print(\"found duplicates\")\n",
    "    for term_id1 in hpo_term_id_set:\n",
    "        for term_id2 in hpo_term_id_set:\n",
    "            # The ancestor, e.g. Seizure comes first, the other term, e.g. Clonic seizure, second\n",
    "            # in the following function call\n",
    "            if hpo.graph.is_ancestor_of(term_id2, term_id1):\n",
    "                redundant_term_d[term_id2] = term_id1\n",
    "    # When we get here, we have scanned all terms for redundant ancestors\n",
    "    non_redundant_terms = set([ tid for tid in hpo_term_ids if tid not in redundant_term_d])\n",
    "    #if len(redundant_term_d) > 0:\n",
    "    #    for term, descendant in redundant_term_d.items():\n",
    "    #        print(f\"Removing redundant_term {term} because of descendent {descendant}\")\n",
    "    return non_redundant_terms\n",
    "\n",
    "\n",
    "def get_clean_terms(pfeatures_list):\n",
    "    \"\"\"\n",
    "    remove terms that are redundant because there is a more specific descendent term\n",
    "    \"\"\"\n",
    "    observed_terms = [t for t in pfeatures_list if not t.excluded]\n",
    "    excluded_terms = [t for t in pfeatures_list if not t.excluded]\n",
    "    observed_d = {t.type.id:t for t in observed_terms}\n",
    "    excluded_d = {t.type.id:t for t in excluded_terms}\n",
    "\n",
    "    observed_ids = fix_redundancies(observed_d.keys())\n",
    "    excluded_ids = fix_redundancies(excluded_d.keys())\n",
    "    clean_terms = []\n",
    "    # this will remove duplicates\n",
    "    seen_tids = set()\n",
    "    for tid in observed_ids:\n",
    "        if tid in seen_tids:\n",
    "            continue\n",
    "        else:\n",
    "            seen_tids.add(tid)\n",
    "        clean_terms.append(observed_d.get(tid))\n",
    "    for tid in excluded_ids:\n",
    "        if tid in seen_tids:\n",
    "            continue\n",
    "        else:\n",
    "            seen_tids.add(tid)\n",
    "        clean_terms.append(excluded_d.get(tid))\n",
    "    return clean_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62022748-1fc4-47b2-b298-9d4443943510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_v2_phenopacket(json_dict):\n",
    "    id = get_id(json_dict)\n",
    "    proband_id, iso_age, sex= get_subject(json_dict)\n",
    "    pfeatures_list = get_phenotypic_features_list(json_dict)\n",
    "    pfeatures_list = get_clean_terms(pfeatures_list)\n",
    "    gene = get_gene(json_dict)\n",
    "    disease = get_disease(json_dict)\n",
    "    interpretation = get_interpretation(json_dict, gene, disease, proband_id)\n",
    "    # Create phenopacket\n",
    "    phenopacket = PPKt.Phenopacket()\n",
    "    phenopacket.id = id\n",
    "    proband = PPKt.Individual()\n",
    "    proband.id = proband_id\n",
    "    if sex == \"MALE\":\n",
    "        proband.sex  = PPKt.Sex.MALE\n",
    "    elif sex == \"FEMALE\":\n",
    "        proband.sex = PPKt.Sex.FEMALE\n",
    "    else:\n",
    "        proband.sex  = PPKt.Sex.UNKNOWN_SEX\n",
    "    if iso_age is not None:\n",
    "        proband.time_at_last_encounter.age.iso8601duration = iso_age\n",
    "    phenopacket.subject.CopyFrom(proband)\n",
    "    for pf in pfeatures_list:\n",
    "        phenopacket.phenotypic_features.append(pf)\n",
    "    d = PPKt.Disease()\n",
    "    d.term.id = disease.get('id')\n",
    "    d.term.label = disease.get('label')\n",
    "    phenopacket.diseases.append(d)\n",
    "    phenopacket.interpretations.append(interpretation)\n",
    "    metadata = get_metadata(json_dict)\n",
    "    phenopacket.meta_data.CopyFrom(metadata)\n",
    "    return phenopacket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be420e84-8e20-4ebf-b703-ab4b257e6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_phenopacket(json_dict, output_dir):\n",
    "    ppack = construct_v2_phenopacket(json_dict)\n",
    "    json_string = MessageToJson(ppack)\n",
    "    pp_id = ppack.id\n",
    "    fname = pp_id.replace(\" \", \"\").replace(\":\", \"_\")\n",
    "    fname = re.sub('[^A-Za-z0-9_-]', '', fname)  # remove any illegal characters from filename\n",
    "    fname = fname.replace(\" \", \"_\") + \".json\"\n",
    "    outpth = os.path.join(output_dir, fname)\n",
    "    with open(outpth, \"wt\") as fh:\n",
    "        fh.write(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1124962-d861-43be-be8a-8521fa2b3868",
   "metadata": {},
   "source": [
    "<h2>Output</h2>\n",
    "<p>Here we output the 384 phenopackets in version 2 format. Some of the original files do not have a valid age string, and so they produce a warning during the output. This can be ignored, the corresponding cases our output without an age (which is not required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdf192e7-66fe-4f70-bfdd-82688994bd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Output 384 phenopackets\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"v2phenopackets\"\n",
    "v1dir = \"v1ppkts\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "n = 0\n",
    "for json_file in jsonfiles:\n",
    "    json_dict = get_json_object(json_file, v1dir)\n",
    "    output_phenopacket(json_dict, out_dir)\n",
    "    print(\".\", end=\"\")\n",
    "    n += 1\n",
    "print(f\"\\nOutput {n} phenopackets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c535af8-e15e-4f84-890f-79df3df0cead",
   "metadata": {},
   "source": [
    "<h2>Additional validation</h2>\n",
    "<p>In the original phenopackets used for the LIRICAL publication, the original cases reports conmtained some redundant HPO terms.\n",
    "<p>This can be detected using <a href=\"http://phenopackets.org/phenopacket-tools/stable/cli.html\">phenopacket tools</a>.\n",
    "<p>We have removed duplicated and redundant terms using the above functions and the following call showed no errors</p>\n",
    "<pre>pxf validate --hpo hp.json *.json</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3af17457-c57e-4af2-a819-3a9b06043a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pyphetools] Ingested 384 GA4GH phenopackets.\n"
     ]
    }
   ],
   "source": [
    "ingestor = PhenopacketIngestor(indir=\"v2phenopackets\")\n",
    "ppkt_d = ingestor.get_phenopacket_dictionary()\n",
    "individuals = [Individual.from_ga4gh_phenopacket(ppkt) for ppkt in ppkt_d.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac8829cd-acda-48a7-a094-124985c4e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvalidator = CohortValidator(cohort=individuals, ontology=hpo, min_hpo=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed9bfe03-317c-428d-94cf-8e5c69c9cb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Cohort validation</h2>\n",
       "<p>No errors found for the cohort with 384 individuals</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "qc = QcVisualizer(cvalidator)\n",
    "display(HTML(qc.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a8e7a-09b8-4a70-8c31-8be303cf74eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
